model:
  latent_dim: 64
  d_model: 256
  n_layers: 6
  n_heads: 8
  n_freq: 32
  element_dim: 7
  lambda_min: 0.01
  lambda_max: 1000.0
  dropout: 0.1
  mlp_ratio: 4

training:
  epochs: 50
  batch_size: 32
  learning_rate: 3.0e-4
  weight_decay: 1.0e-2
  grad_clip: 1.0
  scheduled_sampling_warmup: 10
  scheduled_sampling_k: 0.05
